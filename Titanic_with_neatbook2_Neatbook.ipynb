{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic_with_neatbook2 Neatbook\n",
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "                            Name   Sex    Ticket Cabin Embarked\n",
      "count                        891   891       891   204      889\n",
      "unique                       891     2       681   147        3\n",
      "top     Bonnell, Miss. Elizabeth  male  CA. 2343    G6        S\n",
      "freq                           1   577         7     4      644\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get data here\n",
    "df = pd.read_csv(\"train.csv\") # Edit: Your dataset\n",
    "print(df.describe(include = [np.number]))\n",
    "print(df.describe(include = ['O']))\n",
    "print(df.dtypes)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "className = 'class' # Edit: Replace class with the Y column name\n",
    "trainX, testX, trainY, testY = train_test_split(df.drop([className], axis=1),\n",
    "                                                    df[className], train_size=0.75, test_size=0.25)\n",
    "\n",
    "indexColumns = [] # Edit: Optionally add column names\n",
    "iWillManuallyCleanColumns = [] # Edit: Optionally add column names\n",
    "\n",
    "print(\"trainX\\n\")\n",
    "print(trainX.head())\n",
    "print(\"\\ntrainY\\n\")\n",
    "print(trainY.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neatdata.neatdata import *\n",
    "\n",
    "neatdata =  NeatData()\n",
    "cleanTrainX, cleanTrainY = neatdata.cleanTrainingDataset(trainX, trainY, indexColumns, iWillManuallyCleanColumns)\n",
    "cleanTestX = neatdata.cleanTestDataset(testX)\n",
    "cleanTestY = neatdata.convertYToNumbersForModeling(testY)\n",
    "\n",
    "print(\"Cleaning done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(cleanTrainX.describe(include = [np.number]))\n",
    "print(cleanTrainX.head())\n",
    "\n",
    "print(cleanTrainY)\n",
    "\n",
    "\n",
    "print(cleanTestX.describe(include = [np.number]))\n",
    "print(cleanTestX.head())\n",
    "\n",
    "\n",
    "print(cleanTestY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "tpot = TPOTClassifier(max_time_mins=5, # Edit: Set to 480 to train for 8 hours\n",
    "                      population_size=100, max_eval_time_mins=5, verbosity=2)\n",
    "tpot.fit(cleanTrainX, cleanTrainY)\n",
    "print(tpot.score(cleanTestX, cleanTestY))\n",
    "tpot.export('tpot_pipeline.py')\n",
    "\n",
    "print(\"\\n\\nTPOT is done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this after TPOT is done\n",
    "\n",
    "Creates the modelpipeline.py file.  That file also creates the trainedmodelpipeline.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating modelpipeline.py\n"
     ]
    }
   ],
   "source": [
    "with open('modelpipeline.py', 'w') as fileOut:\n",
    "    with open('tpot_pipeline.py', 'r') as fileIn:\n",
    "        for line in fileIn:\n",
    "            if line.startswith(\"import\") or line.startswith(\"from \"):\n",
    "                fileOut.write(line)\n",
    "    fileOut.write(\"\"\"from sklearn.metrics import accuracy_score\n",
    "from neatdata.neatdata import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "class ModelPipeline:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.indexColumns, self.iWillManuallyCleanColumns = None, None\n",
    "        self.neatData =  NeatData()\n",
    "        self.className = 'class' # Edit: Replace class with the Y column name\n",
    "        self.indexColumns = [] # Edit: Optionally add column names\n",
    "        self.iWillManuallyCleanColumns = [] # Edit: Optionally add column names\n",
    "        self.cleanTrainX, self.cleanTrainY, self.cleanTestX, self.cleanTestY = None, None, None, None\n",
    "        self.results = None\n",
    "\n",
    "\n",
    "    def execute(self):\n",
    "        trainX, testX, trainY, testY = self._getDatasetFrom________() # Edit: choose one of two functions\n",
    "        self._cleanDatasets()\n",
    "        self._modelFit()\n",
    "        self._printModelScores()\n",
    "        self._createTrainedModelPipelineFile()\n",
    "        self._saveObjectsToDisk()\n",
    "        self._createTrainedModelPipelineFile()\n",
    "\n",
    "    def _getDatasetFromOneFile(self):\n",
    "        df = pd.read_csv('iris.csv') # Edit: Your dataset\n",
    "        trainX, testX, trainY, testY = train_test_split(df.drop([self.className], axis=1),\n",
    "                                                         df[self.className], train_size=0.75, test_size=0.25)\n",
    "        return trainX, testX, trainY, testY\n",
    "\n",
    "    def _getDatasetFromTwoFiles(self):\n",
    "        trainingDf = pd.read_csv('train_iris.csv') # Edit: Your training dataset\n",
    "        testDf = pd.read_csv('test_iris.csv') # Edit: Your test dataset\n",
    "        trainX = trainingDf.drop([self.className], axis=1)\n",
    "        trainY = trainingDf[self.className]\n",
    "        testX = testDf.drop([self.className], axis=1)\n",
    "        testY = testDf[self.className]\n",
    "        return trainX, testX, trainY, testY\n",
    "\n",
    "    def _cleanDatasets(self):\n",
    "        self.cleanTrainX, self.cleanTrainY = self.neatData.cleanTrainingDataset(trainX, trainY, indexColumns, iWillManuallyCleanColumns)\n",
    "        self.cleanTestX = self.neatData.cleanTestDataset(testX)\n",
    "        self.cleanTestY = self.neatData.convertYToNumbersForModeling(testY)\n",
    "\n",
    "    def _modelFit(self):\n",
    "\"\"\")\n",
    "\n",
    "showNextLines = False\n",
    "with open('modelpipeline.py', 'a') as fileOut:\n",
    "    with open('tpot_pipeline.py', 'r') as fileIn:\n",
    "        for line in fileIn:\n",
    "            if line.startswith(\"# Score\"):\n",
    "                showNextLines = True\n",
    "            elif showNextLines and not line.startswith(\"exported_pipeline.fit\") and not line.startswith(\"results\"):\n",
    "                fileOut.write(\"        \" + line)\n",
    "\n",
    "with open('modelpipeline.py', 'a') as fileOut:\n",
    "    fileOut.write(\"\"\"        self.exported_pipeline = exported_pipeline\n",
    "        self.exported_pipeline.fit(self.cleanTrainX, self.cleanTrainY)\n",
    "        self.results = self.exported_pipeline.predict(self.cleanTestX)\n",
    "\n",
    "    def _printModelScores(self):\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(self.cleanTestY, self.results))\n",
    "        print(accuracy_score(self.cleanTestY, self.results))\n",
    "\n",
    "    def _saveObjectsToDisk(self):\n",
    "        def save_object(obj, filename):\n",
    "            with open(filename, 'wb') as output:\n",
    "                pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        save_object(self.exported_pipeline, 'exportedPipeline.pkl')\n",
    "        save_object(self.neatData, 'NeatData.pkl')\n",
    "\n",
    "    def _createTrainedModelPipelineFile(self):\n",
    "        with open('trainedmodelpipeline.py', 'w') as fileOut:\n",
    "            fileOut.write(\\\"\\\"\\\"\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "class TrainedModelPipeline:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.exportedPipeline = None\n",
    "        self.neatData = None\n",
    "        self.testX = None\n",
    "        self.cleanTestX = None\n",
    "        self.results = None\n",
    "        self.resultsDf = None\n",
    "\n",
    "    def execute(self):\n",
    "        self._loadObjects()\n",
    "        self._getDataset()\n",
    "        self._cleanDataset()\n",
    "        self._predict()\n",
    "        self._concatenatePredictionsToDataframe()\n",
    "        self._saveResultsAsCSV()\n",
    "        print(\"Done. Created results.csv\")\n",
    "\n",
    "    def _loadObjects(self):\n",
    "        with open('exportedPipeline.pkl', 'rb') as input:\n",
    "            self.exportedPipeline = pickle.load(input)\n",
    "        with open('NeatData.pkl', 'rb') as input:\n",
    "            self.neatData = pickle.load(input)\n",
    "\n",
    "    def _getDataset(self):\n",
    "        self.testX = pd.read_csv('test_iris.csv') # Edit: Your dataset\n",
    "\n",
    "    def _cleanDataset(self):\n",
    "        self.cleanTestX = self.neatData.cleanTestDataset(self.testX)\n",
    "\n",
    "    def _predict(self):\n",
    "        self.results = self.exportedPipeline.predict(self.cleanTestX)\n",
    "        self.results = neatData.convertYToStringsOrNumbersForPresentation(self.results)\n",
    "\n",
    "    def _concatenatePredictionsToDataframe(self):\n",
    "        self.resultsDf = pd.DataFrame(self.results)\n",
    "        self.resultsDf = pd.concat([testX, resultsDf], axis=1)\n",
    "\n",
    "    def _saveResultsAsCSV(self):\n",
    "        self.resultsDf.to_csv('./results.csv')\n",
    "\n",
    "trainedModelPipeline = TrainedModelPipeline()\n",
    "trainedModelPipeline.execute()\n",
    "\\\"\\\"\\\")\n",
    "\n",
    "modelPipeline = ModelPipeline()\n",
    "modelPipeline.execute()\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"Done creating modelpipeline.py\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
